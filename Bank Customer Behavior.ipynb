{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised learning (classification and regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project description\n",
    "Beta Bank customers are leaving: little by little, chipping away every month.\n",
    "The bankers figured out it’s cheaper to save the existing customers rather than\n",
    "to attract new ones. We need to predict whether a customer will leave the bank soon. You have the\n",
    "data on clients’ past behavior and termination of contracts with the bank.\n",
    "Build a model with the maximum possible F1 score. To pass the project, you\n",
    "need an F1 score of at least 0.59. Check the F1 for the test set.\n",
    "Additionally, measure the AUCROC metric and compare it with the F1.\n",
    "Data source: https://www.kaggle.com/barelydedicated/bank-customer-churnmodeling{target=\"blank\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description\n",
    "The data can be found in /datasets/Churn.csv file. Download the dataset.\n",
    "Features\n",
    "RowNumber — data string index\n",
    "CustomerId — unique customer identifier\n",
    "Surname — surname\n",
    "CreditScore — credit score\n",
    "Geography — country of residence\n",
    "Gender — gender\n",
    "Age — age\n",
    "Tenure — period of maturation for a customer’s fixed deposit (years)\n",
    "Balance — account balance\n",
    "NumOfProducts — number of banking products used by the customer\n",
    "HasCrCard — customer has a credit card\n",
    "IsActiveMember — customer’s activeness\n",
    "EstimatedSalary — estimated salary\n",
    "Target\n",
    "Exited — сustomer has left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Download and prepare the data. Explain the procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> It's perfect that all imports are in the first cell!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Remarks: </b> It's better to use <span style=\"font-family: monospace\"> .head() </span> without <span style=\"font-family: monospace\"> print </span> in the notebook.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Tenure'][df['Tenure'].isna() == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  8.,  7.,  4.,  6.,  3., 10.,  5.,  9.,  0., nan])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tenure'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0     952\n",
       "2.0     950\n",
       "8.0     933\n",
       "3.0     928\n",
       "5.0     927\n",
       "7.0     925\n",
       "4.0     885\n",
       "9.0     882\n",
       "6.0     881\n",
       "10.0    446\n",
       "0.0     382\n",
       "Name: Tenure, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tenure'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Remarks: </b> Good that <span style=\"font-family: monospace\"> .unique() </span> was used to view the values. Don't forget about <span style=\"font-family: monospace\"> .value_counts() </span>. This method can be useful to look at the quantity.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tenure'][df['Tenure'].isna() == False].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tenure']=df['Tenure'].fillna(df['Tenure'][df['Tenure'].isna() == False].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were missing values in the Tenure column. I filled them with the median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Remarks: </b> Oops, did you replaced with -1 or with median? Both solutions are OK.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Remarks: </b> May be some features are useles for machine learning model? Try to find and eliminate them. Кeducing the number of features increases the speed of fitting and predicting.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should drop columns that do not predict if a customer will leave. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
       "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
       "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['RowNumber', 'CustomerId', 'Surname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42     2.0       0.00              1   \n",
       "1          608     Spain  Female   41     1.0   83807.86              1   \n",
       "2          502    France  Female   42     8.0  159660.80              3   \n",
       "3          699    France  Female   39     1.0       0.00              2   \n",
       "4          850     Spain  Female   43     2.0  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success (review 2):</b> Good job! These features are really useles.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to do One-Hot Encoding because some features are categorical and others are numerical. This transforms all to numerical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ohe = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> Good job! Using <span style=\"font-family: monospace\"> drop_first=True </span> was a good idea!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_ohe['Exited']\n",
    "features = df_ohe.drop(['Exited'] , axis=1)\n",
    "features_train, features_testvalid, target_train, target_testvalid = train_test_split(features, target, test_size=0.40, random_state=12345)\n",
    "features_test, features_valid, target_test, target_valid = train_test_split(features_testvalid, target_testvalid, test_size=0.50, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set: 20.0 % for features, 20.0 % for target\n"
     ]
    }
   ],
   "source": [
    "print('validation set:', (len(features_valid)/len(features))*100, '% for features,', (len(target_valid)/len(target))*100, '% for target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set: 20.0 % for features, 20.0 % for target\n"
     ]
    }
   ],
   "source": [
    "print('test set:', (len(features_test)/len(features))*100, '% for features,', (len(target_test)/len(target))*100, '% for target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: 60.0 % for features, 60.0 % for target\n"
     ]
    }
   ],
   "source": [
    "print('training set:', (len(features_train)/len(features))*100, '% for features,', (len(target_train)/len(target))*100, '% for target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I finished splitting up my data into a training (60%), validation (20%), and test (20%) set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> Splitting was done perfectly!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Remarks: </b> What about numerical features scaling?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Examine the balance of classes. Train the model without taking into account the imbalance. Briefly describe your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4804\n",
       "1    1196\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Remarks: </b> Using <span style=\"font-family: monospace\"> .mean() </span> with bool target may confuse other scientists. Better to use <span style=\"font-family: monospace\"> .value_counts() </span>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above calculations are the ratios of 1s and 0s. There are a lot more 0s than 1s, causing imbalance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will train a model without taking into account the imbalance. Here is one possible model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=12345,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = f1_score(target_valid, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5030864197530864"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score ends up being lower than the desired f1 score, which is at least 0.59."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip: </b>    Your model parameters is OK, but it is better to use default parameters or tune them. Often default parameters are selected so that the model demonstrates rather good quality.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Improve the quality of the model, taking into account the imbalance of classes. Train different models and find the best one. Briefly describe your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take into account imbalance of classes (need more 1s), class_weight='balanced' does what?, upsample i think, i do not think downsample..., thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_ohe['Exited']\n",
    "features = df_ohe.drop(['Exited'] , axis=1)\n",
    "features_train, features_testvalid, target_train, target_testvalid = train_test_split(features, target, test_size=0.40, random_state=12345)\n",
    "features_test, features_valid, target_test, target_valid = train_test_split(features_testvalid, target_testvalid, test_size=0.50, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I want about 50% of data to be 1s and 50% of data to be 0s, I needed to upsample the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle(upsampled_features_train, upsampled_target_train, random_state=12345)\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "upsampled_features_train, upsampled_target_train = upsample(target=target_train, features=features_train, repeat=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4804\n",
       "1    4784\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled_target_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Needs fixing:</b> OK, no worries, but we have a little error here. Upsampling/downsampling should be applied only to train part (not to valid/test). Applying it to valid/test affects on metrics and they become inflated. Real data is imbalanced so test/valid data should be similar to real data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possibly, downsampling will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345)\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "downsampled_features_train, downsampled_target_train = downsample(features_train, target_train, 0.24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1196\n",
       "0    1153\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled_target_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success (review 2):</b> Well done! Sometimes downsampling performs better.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also adjust the threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold = 0.00 | F1 = 0.444\n",
      "Threshold = 0.02 | F1 = 0.444\n",
      "Threshold = 0.04 | F1 = 0.444\n",
      "Threshold = 0.06 | F1 = 0.444\n",
      "Threshold = 0.08 | F1 = 0.444\n",
      "Threshold = 0.10 | F1 = 0.527\n",
      "Threshold = 0.12 | F1 = 0.527\n",
      "Threshold = 0.14 | F1 = 0.527\n",
      "Threshold = 0.16 | F1 = 0.527\n",
      "Threshold = 0.18 | F1 = 0.527\n",
      "Threshold = 0.20 | F1 = 0.564\n",
      "Threshold = 0.22 | F1 = 0.564\n",
      "Threshold = 0.24 | F1 = 0.564\n",
      "Threshold = 0.26 | F1 = 0.564\n",
      "Threshold = 0.28 | F1 = 0.564\n",
      "Threshold = 0.30 | F1 = 0.590\n",
      "Threshold = 0.32 | F1 = 0.590\n",
      "Threshold = 0.34 | F1 = 0.590\n",
      "Threshold = 0.36 | F1 = 0.590\n",
      "Threshold = 0.38 | F1 = 0.590\n",
      "Threshold = 0.40 | F1 = 0.553\n",
      "Threshold = 0.42 | F1 = 0.553\n",
      "Threshold = 0.44 | F1 = 0.553\n",
      "Threshold = 0.46 | F1 = 0.553\n",
      "Threshold = 0.48 | F1 = 0.553\n",
      "Threshold = 0.50 | F1 = 0.503\n",
      "Threshold = 0.52 | F1 = 0.503\n",
      "Threshold = 0.54 | F1 = 0.503\n",
      "Threshold = 0.56 | F1 = 0.503\n",
      "Threshold = 0.58 | F1 = 0.503\n"
     ]
    }
   ],
   "source": [
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "\n",
    "for threshold in np.arange(0, 0.6, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1 = f1_score(target_valid, predicted_valid)\n",
    "\n",
    "    print(\"Threshold = {:.2f} | F1 = {:.3f}\".format(\n",
    "        threshold, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A threshold of 0.32 has the highest F1 at 0.590."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Success:</b> Well done!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression using upsampled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for Logistic Regression : 0.3895843765648473\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced')\n",
    "model.fit(upsampled_features_train, upsampled_target_train)\n",
    "threshold = 0.32\n",
    "predicted_proba = model.predict_proba(features_valid)\n",
    "predictions = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "score = f1_score(target_valid, predictions)\n",
    "\n",
    "print('f1 score for Logistic Regression',':', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1 score for Logistic Regression lower than our goal (0.59). We can possibly do better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression using downsampled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for Logistic Regression : 0.3880299251870324\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced')\n",
    "model.fit(downsampled_features_train, downsampled_target_train)\n",
    "threshold = 0.32\n",
    "predicted_proba = model.predict_proba(features_valid)\n",
    "predictions = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "score = f1_score(target_valid, predictions)\n",
    "\n",
    "print('f1 score for Logistic Regression',':', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1 score for Logistic Regression lower than our goal (0.59). We can possibly do better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to build a model with the maximum possible F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier using upsampled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for Decision Tree Classifier with 201 depth: 0.484548825710754\n",
      "f1 score for Decision Tree Classifier with 251 depth: 0.484548825710754\n",
      "f1 score for Decision Tree Classifier with 301 depth: 0.484548825710754\n",
      "f1 score for Decision Tree Classifier with 351 depth: 0.484548825710754\n",
      "f1 score for Decision Tree Classifier with 401 depth: 0.484548825710754\n"
     ]
    }
   ],
   "source": [
    "for depth in range(201,402,50):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth, class_weight='balanced')\n",
    "    model.fit(upsampled_features_train, upsampled_target_train)\n",
    "    threshold = 0.32\n",
    "    predicted_proba = model.predict_proba(features_valid)\n",
    "    predictions = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "    score = f1_score(target_valid, predictions)\n",
    "    print('f1 score for Decision Tree Classifier with', depth, 'depth:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1 score for Decision Tree Classifier is lower than our goal (0.59)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier using downsampled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for Decision Tree Classifier with 201 depth: 0.48321048321048327\n",
      "f1 score for Decision Tree Classifier with 301 depth: 0.48321048321048327\n",
      "f1 score for Decision Tree Classifier with 401 depth: 0.48321048321048327\n",
      "f1 score for Decision Tree Classifier with 501 depth: 0.48321048321048327\n",
      "f1 score for Decision Tree Classifier with 601 depth: 0.48321048321048327\n"
     ]
    }
   ],
   "source": [
    "for depth in range(201,602,100):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth, class_weight='balanced')\n",
    "    model.fit(downsampled_features_train, downsampled_target_train)\n",
    "    threshold = 0.32\n",
    "    predicted_proba = model.predict_proba(features_valid)\n",
    "    predictions = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "    score = f1_score(target_valid, predictions)\n",
    "    print('f1 score for Decision Tree Classifier with', depth, 'depth:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1 score for Decision Tree Classifier is lower than our goal (0.59)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier using upsampled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.5171270718232044\n",
      "51 : 0.5921450151057401\n",
      "101 : 0.591321897073663\n",
      "151 : 0.6092184368737474\n",
      "201 : 0.6013986013986014\n",
      "251 : 0.6042296072507553\n",
      "CPU times: user 10.4 s, sys: 14.3 ms, total: 10.4 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for trees in range(1, 301, 50):\n",
    "    model = RandomForestClassifier(random_state=12345, class_weight='balanced', n_estimators=trees, max_depth=50)\n",
    "    model.fit(upsampled_features_train, upsampled_target_train)\n",
    "    threshold = 0.32\n",
    "    predicted_proba = model.predict_proba(features_valid)\n",
    "    predictions = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "    score = f1_score(target_valid, predictions)\n",
    "    print(trees,':', score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest f1 value I found occurred in a Random Forest Classifier model for depth 50 and 151 trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier using downsampled training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.47960033305578686\n",
      "51 : 0.49574885546108566\n",
      "101 : 0.5042567125081859\n",
      "151 : 0.5084967320261438\n",
      "201 : 0.5115055884286653\n",
      "251 : 0.5108338804990151\n",
      "301 : 0.5091863517060368\n",
      "351 : 0.5117801047120419\n",
      "401 : 0.5088062622309198\n",
      "451 : 0.5085190039318479\n",
      "501 : 0.5094957432874918\n",
      "551 : 0.5081645983017635\n",
      "CPU times: user 15.6 s, sys: 103 ms, total: 15.7 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for trees in range(1, 601, 50):\n",
    "    model = RandomForestClassifier(random_state=12345, class_weight='balanced', n_estimators=trees, max_depth=50)\n",
    "    model.fit(downsampled_features_train, downsampled_target_train)\n",
    "    threshold = 0.32\n",
    "    predicted_proba = model.predict_proba(features_valid)\n",
    "    predictions = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "    score = f1_score(target_valid, predictions)\n",
    "    print(trees,':', score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not higher than 0.59. The highest f1 value I found occurred in a Random Forest Classifier model using upsampled training data for depth 50 and 151 trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform the final testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to check the F1 for the test set and measure the AUC-ROC metric to compare it with the F1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.6178010471204187\n",
      "AUC-ROC metric: 0.8376532642950902\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12345, class_weight='balanced', n_estimators=151, max_depth=50)\n",
    "model.fit(upsampled_features_train, upsampled_target_train)\n",
    "\n",
    "test_predict= model.predict(features_test)\n",
    "print('f1:', f1_score(target_test, test_predict))\n",
    "\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "print('AUC-ROC metric:', roc_auc_score(target_test, probabilities_one_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC-ROC and F1 are good if their values are close to 1. To pass the project, I need an F1 score exceeds the goal by 0.2 the AUC-ROC metric is high, showing that this is a good model. I found the best model that I could find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
