{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review (2)\n",
    "\n",
    "Thank you for the fast and correct update. Everything is great now. Also answered your question in the very end of project.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "Hi Julia. As always I've added all my comments to new cells with different coloring.\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "  If you did something great I'm using green color for my comment\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "If I want to give you advice or think that something can be improved, then I'll use yellow. This is an optional recommendation.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "  If the topic requires some extra work so I can accept it then the color will be red\n",
    "</div>\n",
    "\n",
    "You did the project correctly, but you chose irrelevant models for this project. Two of three of your models are regression models while our task is classificational. That is why they showed such poor results. So can you please change your models to correct ones.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi, Julia. This is Soslan. You sent an empty notebook or something happend. Can you please resubmit your project?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi. I renamed my project and then for some reason it did not submit that renamed one and submitted an empty one. Sorry. Now, I know not to rename my projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning: Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mobile carrier Megaline has found out that many of their subscribers use\n",
    "legacy plans. They want to develop a model that would analyze subscribers'\n",
    "behavior and recommend one of Megaline's newer plans: Smart or Ultra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have access to behavior data about subscribers who have already\n",
    "switched to the new plans (from the project for the Statistical Data Analysis\n",
    "course). For this classification task, you need to develop a model that will pick\n",
    "the right plan. Since you’ve already performed the data preprocessing step,\n",
    "you can move straight to creating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop a model with the highest possible accuracy. In this project, the\n",
    "threshold for accuracy is 0.75. Check the accuracy using the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data description\n",
    "Every observation in the dataset contains monthly behavior information about\n",
    "one user. \n",
    "\n",
    "The information given is as follows:\n",
    "\n",
    "сalls — number of calls,\n",
    "\n",
    "minutes — total call duration in minutes,\n",
    "\n",
    "messages — number of text messages,\n",
    "\n",
    "mb_used — Internet traffic used in MB,\n",
    "\n",
    "is_ultra — plan for the current month (Ultra - 1, Smart - 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1) Open and look through the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No missing values and data types are okay. This is a classification task and the target is is_ultra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Split the source data into a training set, a validation set, and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(df, test_size=0.40, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid, df_test = train_test_split(df_valid, test_size=0.50, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: 59.98755444928439 %\n"
     ]
    }
   ],
   "source": [
    "print('training set:', (len(df_train)/len(df))*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set: 20.00622277535781 %\n"
     ]
    }
   ],
   "source": [
    "print('validation set:', (len(df_valid)/len(df))*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set: 20.00622277535781 %\n"
     ]
    }
   ],
   "source": [
    "print('test set:', (len(df_test)/len(df))*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "Good start. Correct split.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 60% of data is training set, 20% of data is validation set, and 20% is test set. The small error is okay and inevitable with computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_features= df_train.drop(['is_ultra'], axis=1)\n",
    "df_train_target= df_train['is_ultra']\n",
    "df_valid_features= df_valid.drop(['is_ultra'], axis=1)\n",
    "df_valid_target= df_valid['is_ultra']\n",
    "df_test_features= df_test.drop(['is_ultra'], axis=1)\n",
    "df_test_target= df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3) Investigate the quality of different models by changing hyperparameters. Briefly describe the findings of the study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "<s>As this is classification task - our targets are classes 0 and 1 - it is better to use here DecisionTreeClassifier, not DecisionTreeRegressor</s>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "Fixed</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 depth 0.7542768273716952 accuracy\n",
      "2 depth 0.7822706065318819 accuracy\n",
      "3 depth 0.7853810264385692 accuracy\n",
      "4 depth 0.7791601866251944 accuracy\n",
      "5 depth 0.7791601866251944 accuracy\n",
      "6 depth 0.7838258164852255 accuracy\n",
      "7 depth 0.7822706065318819 accuracy\n",
      "8 depth 0.7791601866251944 accuracy\n",
      "9 depth 0.7822706065318819 accuracy\n",
      "10 depth 0.7744945567651633 accuracy\n",
      "11 depth 0.7620528771384136 accuracy\n",
      "12 depth 0.7620528771384136 accuracy\n",
      "13 depth 0.7558320373250389 accuracy\n",
      "14 depth 0.7589424572317263 accuracy\n",
      "15 depth 0.7465007776049767 accuracy\n",
      "16 depth 0.7340590979782271 accuracy\n",
      "17 depth 0.7356143079315708 accuracy\n",
      "18 depth 0.7309486780715396 accuracy\n",
      "19 depth 0.7278382581648523 accuracy\n",
      "20 depth 0.7216174183514774 accuracy\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1,21):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(df_train_features, df_train_target)\n",
    "\n",
    "    print(depth, 'depth', model.score(df_valid_features, df_valid_target), 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree with a depth of 6 has the best accuracy ay 78.4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "<s>Same here RandomForestClassiffier will act much better.</s></div>\n",
    "\n",
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "Fixed</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 trees: 0.7853810264385692 accuracy\n",
      "200 trees: 0.7869362363919129 accuracy\n",
      "300 trees: 0.7869362363919129 accuracy\n",
      "400 trees: 0.7853810264385692 accuracy\n",
      "500 trees: 0.7853810264385692 accuracy\n",
      "600 trees: 0.7838258164852255 accuracy\n",
      "700 trees: 0.7822706065318819 accuracy\n",
      "800 trees: 0.7838258164852255 accuracy\n",
      "900 trees: 0.7838258164852255 accuracy\n",
      "1000 trees: 0.7853810264385692 accuracy\n"
     ]
    }
   ],
   "source": [
    "for trees in range(100,1001,100):\n",
    "\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=trees)\n",
    "    model.fit(df_train_features, df_train_target)\n",
    "\n",
    "    print(trees, 'trees:', model.score(df_valid_features, df_valid_target), 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest with 200 trees has the best accuracy of 78.7%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7589424572317263"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345)\n",
    "model.fit(df_train_features, df_train_target)\n",
    "\n",
    "model.score(df_valid_features, df_valid_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "LogisticRegression is the only model I know with word Regression, which used for classification.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Random Forest with 200 trees has the highest accuracy, so I will use this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Check the quality of the model using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=12345,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12345, n_estimators=200)\n",
    "model.fit(df_train_features, df_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7869362363919129"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(df_test_features, df_test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a pretty good accuracy for the test set. It is accurate about 78.7% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Additional task: sanity check the model. This data is more complex than what you’re used to working with, so it’s okay if it doesn’t work out. We'll take a closer look at it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7869362363919129"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(df_test_features, df_test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_ultra'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "choices = [0,1]\n",
    "random_predictions = np.random.choice(choices, size=len(df_test_target))\n",
    "accuracy = accuracy_score(df_test_target, random_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5241057542768274"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "Correct, but for sanity check you can also take model which predicts constantly bigger class - 0. It's accuracy will be about 0.68</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does 'model which predicts constantly biggeer class' mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "As we have more 0s than 1s in target, we can predict only 0s each time and will receive bigger accuracy. That is why accuracy isn't a suitable parameter for prediction of imbalanced classes. Yes, it is dummy model :) Here an explaining code.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6842923794712286"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## reviewer's code\n",
    "\n",
    "zero_predictions = np.zeros(len(df_test_target))\n",
    "accuracy = accuracy_score(df_test_target, zero_predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My model performs better than chance so it passes the sanity check."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
